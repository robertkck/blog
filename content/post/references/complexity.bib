
@book{thurner,
	address = {Oxford, New York},
	title = {Introduction to the {Theory} of {Complex} {Systems}},
	isbn = {978-0-19-882193-9},
	abstract = {This book is a comprehensive introduction to quantitative approaches to complex adaptive systems. Practically all areas of life on this planet are constantly confronted with complex systems, be it ecosystems, societies, traffic, financial markets, opinion formation and spreading, or the internet and social media. Complex systems are systems composed of many elements that interact strongly with each other, which makes them extremely rich dynamical systems showing a huge range of phenomena. Properties of complex systems that are of particular importance are their efficiency, robustness, resilience, and proneness to collapse.The quantitative tools and concepts needed to understand the co-evolutionary nature of networked systems and their properties are challenging. The book gives a self-contained introduction to these concepts, so that the reader will be equipped with a toolset that allows them to engage in the science of complex systems. Topics covered include random processes of path-dependent processes, co-evolutionary dynamics, dynamics of networks, the theory of scaling, and approaches from statistical mechanics and information theory. The book extends beyond the early classical literature in the field of complex systems and summarizes the methodological progress made over the past 20 years in a clear, structured, and comprehensive way.},
	publisher = {Oxford University Press},
	author = {Thurner, Stefan and Hanel, Rudolf and Klimek, Peter},
	month = oct,
	year = {2018},
	file = {Snapshot:C\:\\Users\\KalcikR\\Zotero\\storage\\HBTPEKNX\\introduction-to-the-theory-of-complex-systems-9780198821939.html:text/html}
}



@inproceedings{wang,
	address = {San Francisco, California, USA},
	title = {Structural {Deep} {Network} {Embedding}},
	isbn = {978-1-4503-4232-2},
	url = {http://dl.acm.org/citation.cfm?doid=2939672.2939753},
	doi = {10.1145/2939672.2939753},
	abstract = {Network embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to ﬁnd a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More speciﬁcally, we ﬁrst propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the ﬁrst-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the ﬁrst-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on ﬁve real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network signiﬁcantly better and achieves substantial gains in three applications, i.e. multi-label classiﬁcation, link prediction and visualization.},
	language = {en},
	urldate = {2019-06-01},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} - {KDD} '16},
	publisher = {ACM Press},
	author = {Wang, Daixin and Cui, Peng and Zhu, Wenwu},
	year = {2016},
	pages = {1225--1234},
	file = {Wang et al. - 2016 - Structural Deep Network Embedding.pdf:C\:\\Users\\KalcikR\\Zotero\\storage\\GP9XWMSP\\Wang et al. - 2016 - Structural Deep Network Embedding.pdf:application/pdf}
}

@book{kauffman,
	address = {Oxford, New York},
	title = {Investigations: {Investigations}},
	isbn = {978-0-19-512105-6},
	shorttitle = {Investigations},
	abstract = {In the tradition of Schrödinger's classic What Is Life?, this book is a tour-de-force investigation of the basis of life itself, with conclusions that radically undermine the scientific approaches on which modern science rests-the approaches of Newton, Boltzman, Bohr, and Einstein. Kauffman's At Home in the Universe, which The New York Times Book Review called "passionately written" and nature named "courageous," introduced pivotal ideas about order and evolution in complex life systems. In investigations, Kauffman builds on these theories and finds that classical science does not take into account that physical systems—such as people in a biosphere—effect their dynamic environments in addition to being affected by them. These systems act on their own behalf as autonomous agents, but what defines them as such? In other words, what is life? By defining and explaining autonomous agents and work in the contexts of thermodynamics and of information theory, Kauffman supplies a novel answer to this age-old question that goes beyond traditional scientific thinking. Much of Investigations unpacks the progressively surprising implications of his definition. Kauffman lays out a foundation for a new concept of organization, and explores the requirements for the emergence of a general biology that will transcend terrestrial biology to seek laws governing biospheres anywhere in the cosmos. Moreover, he presents four candidate laws to explain how autonomous agents co-create their biosphere and the startling idea of a "co-creating" cosmos. A showcase of Kauffman's most fundamental and significant ideas, Investigations presents a new way of thinking about the basics of general biology that will change the way we understand life itself—on this planet and anywhere else in the cosmos.},
	publisher = {Oxford University Press},
	author = {Kauffman, Stuart A.},
	month = jan,
	year = {2003},
	file = {Snapshot:C\:\\Users\\KalcikR\\Zotero\\storage\\DTP88I3E\\investigations-9780195121056.html:text/html}
}


@article{goyal,
	title = {Graph {Embedding} {Techniques}, {Applications}, and {Performance}: {A} {Survey}},
	volume = {151},
	issn = {09507051},
	shorttitle = {Graph {Embedding} {Techniques}, {Applications}, and {Performance}},
	url = {http://arxiv.org/abs/1705.02801},
	doi = {10.1016/j.knosys.2018.03.022},
	abstract = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and diﬀerent patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We ﬁrst introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We ﬁnally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a uniﬁed interface to foster and facilitate research on the topic.},
	language = {en},
	urldate = {2019-06-01},
	journal = {Knowledge-Based Systems},
	author = {Goyal, Palash and Ferrara, Emilio},
	month = jul,
	year = {2018},
	note = {arXiv: 1705.02801},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Physics - Data Analysis, Statistics and Probability},
	pages = {78--94},
	annote = {Comment: Submitted to Knowledge Based Systems for review},
	file = {1705.02801.pdf:C\:\\Users\\KalcikR\\Zotero\\storage\\9CTY3K2S\\1705.02801.pdf:application/pdf}
}


@article{straka,
	title = {From {Ecology} to {Finance} (and {Back}?): {A} {Review} on {Entropy}-{Based} {Null} {Models} for the {Analysis} of {Bipartite} {Networks}},
	volume = {173},
	issn = {1572-9613},
	shorttitle = {From {Ecology} to {Finance} (and {Back}?},
	url = {https://doi.org/10.1007/s10955-018-2039-4},
	doi = {10.1007/s10955-018-2039-4},
	abstract = {Bipartite networks provide an insightful representation of many systems, ranging from mutualistic networks of species interactions to investment networks in finance. The analyses of their topological structures have revealed the ubiquitous presence of properties which seem to characterize many—apparently different—systems. Nestedness, for example, has been observed in biological plant-pollinator as well as in country-product exportation networks. Due to the interdisciplinary character of complex networks, tools developed in one field, for example ecology, can greatly enrich other areas of research, such as economy and finance, and vice versa. With this in mind, we briefly review several entropy-based bipartite null models that have been recently proposed and discuss their application to real-world systems. The focus on these models is motivated by the fact that they show three very desirable features: analytical character, general applicability, and versatility. In this respect, entropy-based methods have been proven to perform satisfactorily both in providing benchmarks for testing evidence-based null hypotheses and in reconstructing unknown network configurations from partial information. Furthermore, entropy-based models have been successfully employed to analyze ecological as well as economic systems. As an example, the application of entropy-based null models has detected early-warning signals, both in economic and financial systems, of the 2007–2008 world crisis. Moreover, they have revealed a statistically-significant export specialization phenomenon of country export baskets in international trade, a result that seems to reconcile Ricardo’s hypothesis in classical economics with recent findings on the (empirical) diversification industrial production at the national level. Finally, these null models have shown that the information contained in the nestedness is already accounted for by the degree sequence of the corresponding graphs.},
	language = {en},
	number = {3},
	urldate = {2019-01-16},
	journal = {Journal of Statistical Physics},
	author = {Straka, Mika J. and Caldarelli, Guido and Squartini, Tiziano and Saracco, Fabio},
	month = nov,
	year = {2018},
	keywords = {Bipartite networks, Entropy-based null models, Exponential random graph, Nestedness, Systemic risk, Trade specialization},
	pages = {1252--1285},
	file = {Straka et al_2018_From Ecology to Finance (and Back.pdf:C\:\\Users\\KalcikR\\Zotero\\storage\\KPB5S2VQ\\Straka et al_2018_From Ecology to Finance (and Back.pdf:application/pdf}
}

@article{cai,
	title = {A {Comprehensive} {Survey} of {Graph} {Embedding}: {Problems}, {Techniques} and {Applications}},
	shorttitle = {A {Comprehensive} {Survey} of {Graph} {Embedding}},
	url = {http://arxiv.org/abs/1709.07604},
	abstract = {Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can beneﬁt a lot of useful applications such as node classiﬁcation, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efﬁcient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We ﬁrst introduce the formal deﬁnition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work address these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efﬁciency, problem settings, techniques and application scenarios.},
	language = {en},
	urldate = {2019-06-01},
	journal = {arXiv:1709.07604 [cs]},
	author = {Cai, Hongyun and Zheng, Vincent W. and Chang, Kevin Chen-Chuan},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.07604},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: A 20-page comprehensive survey of graph/network embedding for over 150+ papers till year 2018. It provides systematic categorization of problems, techniques and applications. Accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE). Comments and suggestions are welcomed for continuously improving this survey},
	file = {Cai et al. - 2017 - A Comprehensive Survey of Graph Embedding Problem.pdf:C\:\\Users\\KalcikR\\Zotero\\storage\\IKCU5WEJ\\Cai et al. - 2017 - A Comprehensive Survey of Graph Embedding Problem.pdf:application/pdf}
}



@article{loreto,
	title = {Dynamics on expanding spaces: modeling the emergence of novelties},
	shorttitle = {Dynamics on expanding spaces},
	url = {http://arxiv.org/abs/1701.00994},
	doi = {10.1007/978-3-319-24403-7_5},
	abstract = {Novelties are part of our daily lives. We constantly adopt new technologies, conceive new ideas, meet new people, experiment with new situations. Occasionally, we as individuals, in a complicated cognitive and sometimes fortuitous process, come up with something that is not only new to us, but to our entire society so that what is a personal novelty can turn into an innovation at a global level. Innovations occur throughout social, biological and technological systems and, though we perceive them as a very natural ingredient of our human experience, little is known about the processes determining their emergence. Still the statistical occurrence of innovations shows striking regularities that represent a starting point to get a deeper insight in the whole phenomenology. This paper represents a small step in that direction, focusing on reviewing the scientific attempts to effectively model the emergence of the new and its regularities, with an emphasis on more recent contributions: from the plain Simon's model tracing back to the 1950s, to the newest model of Polya's urn with triggering of one novelty by another. What seems to be key in the successful modelling schemes proposed so far is the idea of looking at evolution as a path in a complex space, physical, conceptual, biological, technological, whose structure and topology get continuously reshaped and expanded by the occurrence of the new. Mathematically it is very interesting to look at the consequences of the interplay between the "actual" and the "possible" and this is the aim of this short review.},
	urldate = {2017-03-14},
	journal = {arXiv:1701.00994 [physics]},
	author = {Loreto, Vittorio and Servedio, Vito D. P. and Strogatz, Steven H. and Tria, Francesca},
	year = {2016},
	note = {arXiv: 1701.00994},
	keywords = {tbr, Physics - Physics and Society},
	pages = {59--83},
	annote = {Comment: 25 pages, 10 figures},
	file = {arXiv.org Snapshot:C\:\\Users\\KalcikR\\Zotero\\storage\\X9VPU7IW\\1701.html:text/html;Loreto et al. - 2016 - Dynamics on expanding spaces modeling the emergen.pdf:C\:\\Users\\KalcikR\\Zotero\\storage\\RIG7IG7F\\Loreto et al. - 2016 - Dynamics on expanding spaces modeling the emergen.pdf:application/pdf}
}

@article{mealy,
	title = {Interpreting economic complexity},
	volume = {5},
	copyright = {Copyright © 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution License 4.0 (CC BY).. This is an open-access article distributed under the terms of the Creative Commons Attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	issn = {2375-2548},
	url = {http://advances.sciencemag.org/content/5/1/eaau1705},
	doi = {10.1126/sciadv.aau1705},
	abstract = {Two network measures known as the economic complexity index (ECI) and product complexity index (PCI) have provided important insights into patterns of economic development. We show that the ECI and PCI are equivalent to a spectral clustering algorithm that partitions a similarity graph into two parts. The measures are also closely related to various dimensionality reduction methods, such as diffusion maps and correspondence analysis. Our results shed new light on the ECI’s empirical success in explaining cross-country differences in gross domestic product per capita and economic growth, which is often linked to the diversity of country export baskets. In fact, countries with high (low) ECI tend to specialize in high-PCI (low-PCI) products. We also find that the ECI and PCI uncover specialization patterns across U.S. states and U.K. regions.
Beyond diversity, towards similarity: Math of economic complexity uncovers specialization patterns across countries and regions.
Beyond diversity, towards similarity: Math of economic complexity uncovers specialization patterns across countries and regions.},
	language = {en},
	number = {1},
	urldate = {2019-01-11},
	journal = {Science Advances},
	author = {Mealy, Penny and Farmer, J. Doyne and Teytelboym, Alexander},
	month = jan,
	year = {2019},
	pages = {eaau1705},
	file = {Full Text PDF:C\:\\Users\\KalcikR\\Zotero\\storage\\W5YPNPAK\\W5YPNPAK.pdf:application/pdf;Snapshot:C\:\\Users\\KalcikR\\Zotero\\storage\\WT5R5TTG\\eaau1705.html:text/html}
}


@article{farmer,
	title = {How predictable is technological progress?},
	volume = {45},
	issn = {0048-7333},
	url = {//www.sciencedirect.com/science/article/pii/S0048733315001699},
	doi = {10.1016/j.respol.2015.11.001},
	abstract = {Recently it has become clear that many technologies follow a generalized version of Moore's law, i.e. costs tend to drop exponentially, at different rates that depend on the technology. Here we formulate Moore's law as a correlated geometric random walk with drift, and apply it to historical data on 53 technologies. We derive a closed form expression approximating the distribution of forecast errors as a function of time. Based on hind-casting experiments we show that this works well, making it possible to collapse the forecast errors for many different technologies at different time horizons onto the same universal distribution. This is valuable because it allows us to make forecasts for any given technology with a clear understanding of the quality of the forecasts. As a practical demonstration we make distributional forecasts at different time horizons for solar photovoltaic modules, and show how our method can be used to estimate the probability that a given technology will outperform another technology at a given point in the future.},
	number = {3},
	urldate = {2017-01-23},
	journal = {Research Policy},
	author = {Farmer, J. Doyne and Lafond, François},
	month = apr,
	year = {2016},
	keywords = {Forecasting, Moore's law, Solar energy, Technological progress},
	pages = {647--665},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\KalcikR\\Zotero\\storage\\4DNSGUS9\\Farmer and Lafond - 2016 - How predictable is technological progress.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\KalcikR\\Zotero\\storage\\G7D86S24\\S0048733315001699.html:text/html}
}

@article{hamilton,
	title = {Representation {Learning} on {Graphs}: {Methods} and {Applications}},
	shorttitle = {Representation {Learning} on {Graphs}},
	url = {http://arxiv.org/abs/1709.05584},
	abstract = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.},
	urldate = {2018-12-20},
	journal = {arXiv:1709.05584 [cs]},
	author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.05584},
	keywords = {Computer Science - Social and Information Networks, Computer Science - Machine Learning},
	annote = {Comment: Published in the IEEE Data Engineering Bulletin, September 2017; version with minor corrections},
	file = {arXiv.org Snapshot:C\:\\Users\\KalcikR\\Zotero\\storage\\5SK7VCPK\\1709.html:text/html;Hamilton et al_2017_Representation Learning on Graphs.pdf:C\:\\Users\\KalcikR\\Zotero\\storage\\BZKG56SJ\\Hamilton et al_2017_Representation Learning on Graphs.pdf:application/pdf}
}



@techreport{uhlbach,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {R\&{D} {Policy} and {Technological} {Trajectories} of {Regions}: {Evidence} from the {EU} {Framework} {Programmes}},
	shorttitle = {R\&{D} {Policy} and {Technological} {Trajectories} of {Regions}},
	url = {https://papers.ssrn.com/abstract=3027919},
	abstract = {It is widely acknowledged that new technological specializations of regions are to a large extent driven by the recombination of existing knowledge and capabilities. Since this process is path-dependent and self-reinforcing, it can easily lead to technological lock-ins. A key issue is therefore to evaluate whether public policy can impact technological trajectories of regions and how it can be more effective. To address this issue, we analyze quantitatively and systematically the relation between R\&D subsidies and new technological specializations of European regions from 1999 to 2010. R\&D subsidies are identified by using the EU Framework Programmes (FP) from the EUPRO database, and matched with patent documents from the OECD-REGPAT database. Using a fixed-effects linear probability model, our results indicate that FP participation have a positive but relatively small effect on the development of new specializations of regions, and that it can compensate for a lack of local related capabilities. We also find evidence that R\&D subsidies have the highest impact if the level of relatedness with the new technology is neither too low (policy cannot build a cathedral in the desert) nor too high (if all the capabilities are already present there is no need for policy).},
	language = {en},
	number = {ID 3027919},
	urldate = {2019-06-01},
	institution = {Social Science Research Network},
	author = {Uhlbach, Wolf-Hendrik and Balland, Pierre Alexandre and Scherngell, Thomas},
	month = aug,
	year = {2017},
	keywords = {EU Framework Programmes, R\&D subsidies, Regional Diversification, Technological Change},
	file = {Snapshot:C\:\\Users\\KalcikR\\Zotero\\storage\\BUW7RX7L\\papers.html:text/html}
}

@article{agrawal,
	title = {Finding {Needles} in {Haystacks}: {Artificial} {Intelligence} and {Recombinant} {Growth}},
	abstract = {In many fields, innovation is predicated on discovering useful new combinations of existing knowledge in highly complex knowledge spaces. Such needle-in-a-haystack problems are pervasive in fields like genomics, drug discovery, materials science, and particle physics. We develop a combinatorial-based knowledge production function and embed it in the classic Jones growth model (1995) to explore how breakthroughs in artificial intelligence (AI) that dramatically improve prediction accuracy about which combinations are most valuable could enhance discovery rates and consequently economic growth. This production function is a generalization (and reinterpretation) of the Romer/Jones knowledge production function. Separate parameters control the extent of individual-researcher knowledge access, the effects of fishing out/complexity, and the ease of forming research teams.},
	language = {en},
	author = {Agrawal, Ajay and McHale, John and Oettl, Alexander},
	year = {2017},
	pages = {39},
	file = {Agrawal et al. - Finding Needles in Haystacks Artificial Intellige.pdf:C\:\\Users\\KalcikR\\Zotero\\storage\\G28L6UMD\\Agrawal et al. - Finding Needles in Haystacks Artificial Intellige.pdf:application/pdf}
}
